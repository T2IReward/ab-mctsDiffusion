# 如何剪枝

# 自适应步长树搜索
## 目标： 让MCTS学会“跳跃式”去噪，即动态选择最优的去噪步长 k，以最高效的方式达到高质量的最终图像。

## 构建： 信息增益评估器 ，是一个神经网络，输入为当前带噪图像 x_t 和时间步 t，以及一个候选步长 k。输出是对信息增益的预测。
输入： (U-Net(x_t, t)的特征, t, k)。latent空间的值。t 和 k 可以作为条件输入。
输出（两种方案）：
奖励变化率预测 (Reward Gradient Prediction): 预测 (LPO(x_{t-k}) - LPO(x_t)) / k。即“每一步的平均奖励提升”。这个目标最直接。

（？？？）最终图像相似度预测 (Final Image Similarity Prediction): 预测 x_{t-k} 与最终生成的 x_0 之间的相似度。这需要一个预训练的模型来预测 x_0 的特征，可能更复杂但更本质。（Step-level Reward for Free in RL-based T2I Diffusion Model Fine-tuning
https://arxiv.org/pdf/2505.19196）
训练数据：
离线生成： 运行大量的标准DDIM或DDPM去噪过程。在每个轨迹上，记录下所有的 (x_t, t)，并计算出所有可能的 k 对应的真实信息增益。
在线微调： 在MCTS搜索过程中，不断收集新的数据点，并用这些“专家数据”来微调IGE模型。

扩展 (Expansion) 阶段：

当选择一个叶子节点 N(x_t, t) 进行扩展时，不再是只生成 x_{t-1}。
而是首先查询IGE模型，输入 (特征(x_t), t, k)，其中 k 来自一个预定义的候选集，例如 K = {1, 2, 4, 8}（步长必须小于等于 t）。
IGE会为每个 k 预测一个信息增益 g_k。
根据这些 g_k，选择一个或多个最有潜力的 k 来执行真正的去噪，生成新的子节点 N'(x_{t-k}, t-k)。例如，可以选择 g_k 最高的那个 k。

# 探索一个分布而非节点

## 目标： 将MCTS从寻找单一最优路径，转变为引导一个状态分布向高奖励区域演化，通过融合多个优秀候补来创造出更优的中间状态。

## 构建
A. 分布式节点表示

在MCTS的树结构中，从同一个父节点 N(x_t) 扩展出的多个子节点 {N_1(x_{t-1}^{(1)}), N_2(x_{t-1}^{(2)}), ...} 被视为一个粒子集，共同代表了 P(x_{t-1}|x_t) 的一个经验近似。
B. 最优传输融合模块 (OT Fusion Module)

触发时机： 当一个节点的探索次数达到一定阈值（例如，已经“走宽”了10次），或者在选择阶段决定“深入”时触发。
输入： 粒子集 {x_{t-1}^{(i)}} 和它们各自的LPO分数 {r_i}。
核心算法 (Wasserstein Barycenter):
权重分配： 根据奖励 r_i 给每个粒子 x_{t-1}^{(i)} 分配一个权重 w_i。一个简单的做法是 w_i = softmax(r_i / τ)，其中 τ 是温度参数。
计算重心： 求解Wasserstein重心的优化问题：
x_{t-1}^* = argmin_x Σ_i w_i * W_2^2(x, x_{t-1}^{(i)})
其中 W_2^2 是平方Wasserstein-2距离。直接在像素空间计算是不可行的。
在潜在空间计算： 解决方案是在一个有意义的潜在空间中计算。可以使用预训练的VAE的编码器 E 将图像映射到潜在空间 z = E(x)，或者使用U-Net自身的中间层特征。在 z 空间计算重心 z^*，然后用VAE的解码器 D 或者一个专门训练的映射网络将其映射回图像空间 x_{t-1}^* = D(z^*)。
输出： 一个全新的、融合了多个父粒子优点的节点 N^*(x_{t-1}^*)。

C. MCTS搜索过程的改造

新的动作：“融合深入” (Fuse-and-Deepen):
在选择阶段，除了“走宽”和“从某个已有子节点深入”外，增加第三个选项：“融合深入”。
这个动作的价值可以通过其粒子集成员的平均奖励来估计。
树结构的动态变化：
当执行“融合深入”后，新的融合节点 N^* 被添加到树中，成为父节点 N 的一个特殊子节点。后续的探索将从 N^* 开始。
原来的粒子节点可以被保留用于后续可能的其他融合，或者被剪枝。



例子太简单

路径就是找错了？（暂时以reward作为指标，所有完成结果也没有特别突出的）算法本身是否有效

奖励模型是否有效，重训？

调度器,不同的影响？ 自适应步长

剪枝

## 测量奖励模型是否合理
